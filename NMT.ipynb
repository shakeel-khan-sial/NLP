{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov5Llt7czE_S"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BZ1w6h5zjGn"
      },
      "source": [
        "\n",
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "    # open the file\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djk1Gn68zmS7"
      },
      "source": [
        "# split a text into sentences\n",
        "def to_lines(text):\n",
        "    sents = text.strip().split('\\n')\n",
        "    sents = [i.split('\\t') for i in sents]\n",
        "    return sents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eMkgE62zpCt"
      },
      "source": [
        "data = read_text(\"/content/deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pGpa8j3nhXH",
        "outputId": "c89ada57-1302-4ccf-9a7d-35b2302d86cb"
      },
      "source": [
        "len(deu_eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtAoR2Ot0M_c"
      },
      "source": [
        "\n",
        "deu_eng = deu_eng[:100000,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn2I4IK60Pxz",
        "outputId": "a44bc691-af91-4957-f180-8a35240326df"
      },
      "source": [
        "\n",
        "deu_eng"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Geh.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
              "       ['Hi.', 'Hallo!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['Hi.', 'Grüß Gott!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ...,\n",
              "       [\"It's good to see you smile.\",\n",
              "        'Es ist schön, dich lächeln zu sehen.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4832310 (Hybrid) & #6128764 (Pfirsichbaeumchen)'],\n",
              "       [\"It's good to see you smile.\",\n",
              "        'Es ist schön, Sie lächeln zu sehen.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4832310 (Hybrid) & #6128766 (Pfirsichbaeumchen)'],\n",
              "       [\"It's hard to say no to Tom.\",\n",
              "        'Es ist schwer, Tom etwas abzuschlagen.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #3394352 (CK) & #3411708 (Pfirsichbaeumchen)']],\n",
              "      dtype='<U120')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO6VXIro0Pu0"
      },
      "source": [
        "# Remove punctuation\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cSX3t1s0Pry",
        "outputId": "37aac52d-7fa1-4915-c86e-f3c701f37f8c"
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go', 'Geh',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
              "       ['Hi', 'Hallo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['Hi', 'Grüß Gott',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ...,\n",
              "       ['Its good to see you smile',\n",
              "        'Es ist schön dich lächeln zu sehen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4832310 (Hybrid) & #6128764 (Pfirsichbaeumchen)'],\n",
              "       ['Its good to see you smile', 'Es ist schön Sie lächeln zu sehen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4832310 (Hybrid) & #6128766 (Pfirsichbaeumchen)'],\n",
              "       ['Its hard to say no to Tom',\n",
              "        'Es ist schwer Tom etwas abzuschlagen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #3394352 (CK) & #3411708 (Pfirsichbaeumchen)']],\n",
              "      dtype='<U120')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50nCKuGU0Pli"
      },
      "source": [
        "# convert to lowercase\n",
        "for i in range(len(deu_eng)):\n",
        "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "    \n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjZ2dgP70PiD",
        "outputId": "1a39daf4-056f-41ba-dbcd-277614643714"
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['go', 'geh',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
              "       ['hi', 'hallo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['hi', 'grüß gott',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ...,\n",
              "       ['its good to see you smile',\n",
              "        'es ist schön dich lächeln zu sehen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4832310 (Hybrid) & #6128764 (Pfirsichbaeumchen)'],\n",
              "       ['its good to see you smile', 'es ist schön sie lächeln zu sehen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4832310 (Hybrid) & #6128766 (Pfirsichbaeumchen)'],\n",
              "       ['its hard to say no to tom',\n",
              "        'es ist schwer tom etwas abzuschlagen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #3394352 (CK) & #3411708 (Pfirsichbaeumchen)']],\n",
              "      dtype='<U120')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A--1Yna0ZnJ"
      },
      "source": [
        "# empty lists\n",
        "eng_l = []\n",
        "deu_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in deu_eng[:,0]:\n",
        "    eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "    deu_l.append(len(i.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rOVbmms0Zjy"
      },
      "source": [
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "yPrtQiaH0Zha",
        "outputId": "5572488f-0f24-4211-caaf-8912526bfd25"
      },
      "source": [
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHa3v2PF0ZeL"
      },
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC-iD48D0Zac",
        "outputId": "8821ed96-fe74-4042-f404-f8e7a8c92f06"
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 8955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxp490Pg0PeS",
        "outputId": "dab877b3-0910-4a31-dadb-382f8e09f780"
      },
      "source": [
        "\n",
        "# prepare Deutch tokenizer\n",
        "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "deu_length = 8\n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deutch Vocabulary Size: 15980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LYVxTfs0x-f"
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd1-w1Fu00zS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtqSy6Rd06XD"
      },
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo2Kdkly06-q"
      },
      "source": [
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV3WLe3s1AQR"
      },
      "source": [
        "\n",
        "# build NMT model\n",
        "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "    model.add(LSTM(units))\n",
        "    model.add(RepeatVector(out_timesteps))\n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(Dense(out_vocab, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Red5uKsC1EOt"
      },
      "source": [
        "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
        "rms = optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf0BlgSu1Gwj",
        "outputId": "f8558ee7-95d6-4a71-cf69-6a2b9cc2b4c1"
      },
      "source": [
        "filename = 'model.h7.29_jul_21'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
        "          epochs=30, batch_size=512, \n",
        "          validation_split = 0.2,\n",
        "          callbacks=[checkpoint], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "125/125 [==============================] - 573s 4s/step - loss: 4.2823 - val_loss: 3.4322\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.43224, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/30\n",
            "125/125 [==============================] - 547s 4s/step - loss: 3.1370 - val_loss: 2.9387\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.43224 to 2.93874, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/30\n",
            "125/125 [==============================] - 547s 4s/step - loss: 2.8303 - val_loss: 2.7258\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.93874 to 2.72584, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/30\n",
            "125/125 [==============================] - 545s 4s/step - loss: 2.6007 - val_loss: 2.5251\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.72584 to 2.52513, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/30\n",
            "125/125 [==============================] - 545s 4s/step - loss: 2.3843 - val_loss: 2.3615\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.52513 to 2.36148, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/30\n",
            "125/125 [==============================] - 545s 4s/step - loss: 2.2073 - val_loss: 2.2037\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.36148 to 2.20366, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/30\n",
            "125/125 [==============================] - 541s 4s/step - loss: 2.0131 - val_loss: 2.0502\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.20366 to 2.05015, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/30\n",
            "125/125 [==============================] - 542s 4s/step - loss: 1.8273 - val_loss: 1.9243\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.05015 to 1.92427, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/30\n",
            "125/125 [==============================] - 547s 4s/step - loss: 1.6649 - val_loss: 1.8084\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.92427 to 1.80843, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/30\n",
            "125/125 [==============================] - 542s 4s/step - loss: 1.5188 - val_loss: 1.7301\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.80843 to 1.73009, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/30\n",
            "125/125 [==============================] - 543s 4s/step - loss: 1.3902 - val_loss: 1.6415\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.73009 to 1.64152, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/30\n",
            "125/125 [==============================] - 545s 4s/step - loss: 1.2684 - val_loss: 1.5736\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.64152 to 1.57356, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/30\n",
            "125/125 [==============================] - 542s 4s/step - loss: 1.1582 - val_loss: 1.5183\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.57356 to 1.51827, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/30\n",
            "125/125 [==============================] - 545s 4s/step - loss: 1.0604 - val_loss: 1.4906\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.51827 to 1.49060, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/30\n",
            "125/125 [==============================] - 539s 4s/step - loss: 0.9714 - val_loss: 1.4608\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.49060 to 1.46077, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/30\n",
            "125/125 [==============================] - 539s 4s/step - loss: 0.8937 - val_loss: 1.4169\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.46077 to 1.41689, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/30\n",
            "125/125 [==============================] - 539s 4s/step - loss: 0.8203 - val_loss: 1.3840\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.41689 to 1.38400, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/30\n",
            "125/125 [==============================] - 539s 4s/step - loss: 0.7504 - val_loss: 1.3657\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.38400 to 1.36568, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/30\n",
            "125/125 [==============================] - 539s 4s/step - loss: 0.6926 - val_loss: 1.3531\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.36568 to 1.35313, saving model to model.h7.29_jul_21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h7.29_jul_21/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/30\n",
            "125/125 [==============================] - 541s 4s/step - loss: 0.6317 - val_loss: 1.3745\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.35313\n",
            "Epoch 21/30\n",
            " 88/125 [====================>.........] - ETA: 2:28 - loss: 0.5695"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLcSKP2i3WVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9baed3e1-8c43-4a2c-876f-a8d05969c565"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCeQV94i-XR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c9a93c-63d6-4b4e-a78b-062c7df58f48"
      },
      "source": [
        "testX.reshape(testX.shape[0],testX.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  218,    4, ...,    0,    0,    0],\n",
              "       [   1,   49,    6, ...,  401,   12,  115],\n",
              "       [   2,  990,   40, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 187,    1,   48, ...,    0,    0,    0],\n",
              "       [   7,   41,  104, ...,    0,    0,    0],\n",
              "       [   1,   19, 3862, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehT125yA-bug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432a5628-1909-4f46-b7d2-6fe907093263"
      },
      "source": [
        "testX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  218,    4, ...,    0,    0,    0],\n",
              "       [   1,   49,    6, ...,  401,   12,  115],\n",
              "       [   2,  990,   40, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 187,    1,   48, ...,    0,    0,    0],\n",
              "       [   7,   41,  104, ...,    0,    0,    0],\n",
              "       [   1,   19, 3862, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJJTrfQ3-AHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d581226e-f1bb-49f3-cee0-e084872a710b"
      },
      "source": [
        "(testX.reshape((testX.shape[0], testX.shape[1]))).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU-K-_Ib3W3W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "2d2358e7-a917-4008-96f7-5853b91ade3b"
      },
      "source": [
        "model = load_model('/content/model.h7.29_jul_21')\n",
        "preds = model.predict_classes(testX.reshape(testX.shape[0],testX.shape[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-936a981a4ac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model.h7.29_jul_21'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1700\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,8,8955] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential/dense/Softmax (defined at /usr/local/lib/python3.7/dist-packages/keras/activations.py:80) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_487946]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential/dense/Softmax:\n sequential/dense/BiasAdd (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/core.py:1233)\n\nFunction call stack:\npredict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mASTAEeb4N3R"
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSPeTNc38-Xr"
      },
      "source": [
        "\n",
        "# convert predictions into text (English)\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "             \n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)            \n",
        "        \n",
        "    preds_text.append(' '.join(temp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LJzXAq99EZH"
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhky2VaTnHL9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ82H7tt9Im5"
      },
      "source": [
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb0Bpv2K9dud"
      },
      "source": [
        "\n",
        "pred_df.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y14tFFYNCw4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHavX2wCCw2L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYJUI3kzCx-A"
      },
      "source": [
        "Testing on email data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJeje3YUCzvF"
      },
      "source": [
        "stringg = \"\"\"Guten Morgen Herr Tabib,\n",
        " \n",
        "bin auf der Suche nach MCS7830CV-DA\n",
        " \n",
        "Verical hat zwar 589 Stück am Lager , die reichen uns aber nicht.\n",
        "Brauche eventuell 1000 weitere.\n",
        " \n",
        "Angebot für 1k   MCS7830CV-DA  möglich? \"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nqT1zadC2IP"
      },
      "source": [
        "# split text into sentences \n",
        "def to_lines(text): \n",
        "      sents = text.strip().split('\\n') \n",
        "      sents = [i.split('\\t') for i in sents] \n",
        "      return sents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yu4sTxQC4c1"
      },
      "source": [
        "import numpy as np\n",
        "data = stringg\n",
        "input = to_lines(data)\n",
        "input = array(input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldZANXjrC7Cb"
      },
      "source": [
        "input = [(str(s)).translate(str.maketrans('','',string.punctuation)) for s in input]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BstnsLtrC95R"
      },
      "source": [
        "type(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w963aYtoFqoK"
      },
      "source": [
        "input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwacad3OEpDb"
      },
      "source": [
        "a = []\n",
        "for word in input:\n",
        "  a.append(word.lower())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIKtZ620FyN9"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRsl8czYF3JJ"
      },
      "source": [
        "input = a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0odrEWcsMmAt"
      },
      "source": [
        "len(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-ruKAXRDFQB"
      },
      "source": [
        "eng_l = [] \n",
        "for i in input:\n",
        "      eng_l.append(len(i.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jESVJI6DJAH"
      },
      "source": [
        "length_df = pd.DataFrame({'eng':eng_l, })\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhmCzJdYF_X0"
      },
      "source": [
        "def tokenization(lines): \n",
        "      tokenizer = Tokenizer() \n",
        "      tokenizer.fit_on_texts(lines) \n",
        "      return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URuuBdVlGCZB"
      },
      "source": [
        "eng_tokenizer = tokenization(input) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFheTtBDH_Jh"
      },
      "source": [
        "eng_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUIiFk6YGEu3"
      },
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wI96c7-GGzZ"
      },
      "source": [
        "eng_vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK2wrmseGIQ4"
      },
      "source": [
        "eng_length = 8 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0qUbr13GLDp"
      },
      "source": [
        "# encode and pad sequences \n",
        "def encode_sequences(tokenizer, length, lines):          \n",
        "         # integer encode sequences          \n",
        "         seq = tokenizer.texts_to_sequences(lines)          \n",
        "         # pad sequences with 0 values          \n",
        "         seq = pad_sequences(seq, maxlen=length, padding='post')           \n",
        "         return seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSnfKfa5GNbo"
      },
      "source": [
        "testX = encode_sequences(eng_tokenizer,eng_length, input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uRSNgA2IC7w"
      },
      "source": [
        "testX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbT9bwcaGQHt"
      },
      "source": [
        "model = load_model('/content/model.h7.28_jul_21')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4x-RI2ZGXHr"
      },
      "source": [
        "preds = model.predict_classes(testX.reshape(testX.shape[0], testX.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKafyFiyGdza"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAYcj5nlGeNu"
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == n:\n",
        "      return word\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa2Qm9ZIGiSi"
      },
      "source": [
        "# convert predictions into text (English)\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "             \n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)            \n",
        "        \n",
        "    preds_text.append(' '.join(temp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAIzsZR5Gxzy"
      },
      "source": [
        "preds_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nukEMgISHNHe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}